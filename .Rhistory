# Load the CCxG propbank-annotated .json corpus data
corpus_df <- fromJSON(raw_data_file)
# Convert JSON data to data frame
corpus_df <- as.data.frame(corpus_df)
# Extract the roles from the data frame
roles <- corpus_df[["roles"]]
# Extract the rolesets from the roles data frame
roleset_df <- data.frame(roleset = unlist(lapply(roles, function(x) x$roleset)))
# Remove NA values
roleset_df <- na.omit(roleset_df)
# Extract the rolesets from the roles data frame
lemma_df <- data.frame(lemma = unlist(lapply(roles, function(x) x$lemma)))
# Remove NA values
lemma_df <- na.omit(lemma_df)
add_lemma_column <- function(corpus_df, lemma_df) {
corpus_df$lemma <- lemma_df$lemma
return(corpus_df)
}
corpus_df <- add_lemma_column(corpus_df, lemma_df)
# Function that adds an additional column to a dataframe
# The new column is called argument_structure_construction and is a combination of roleType and pos
add_arg_struct <- function(data_frame) {
# Add a new column called 'argument_structure_construction' to the data frame
data_frame$argument_structure_construction <- sapply(data_frame$roles, function(x) {
# Concatenate the roleType and pos columns into a string like 'arg0(np)'
role_strings <- paste0(x$roleType, "(", x$pos, ")")
# Collapse the role strings into a single string separated by '-'
return(paste(role_strings, collapse = "-"))
})
# Return the modified data frame
return(data_frame)
}
# Run the add add_arg_struct function to the corpus dataframe
corpus_df <- add_arg_struct(corpus_df)
# Function that creates the dataframe used for the analysis
# It combines the argument structure and roleset into a dataframe
combine_arg_struct_and_roleset <- function(corpus, rolesets, lemmas) {
corpus_analysis_df <- data.frame(arg_struc_cxn = corpus$argument_structure_construction, roleset = rolesets$roleset, lemma = lemmas$lemma)
return(corpus_analysis_df)
}
corpus_analysis_df <- combine_arg_struct_and_roleset(corpus_df, roleset_df, lemma_df)
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
###freq_table <- count_frequency(corpus_analysis_df)
###cxn_for_multiple <- filter_by_n_most_frequent_arg_struc_cxn(corpus_analysis_df, 50)
df_cxn_lemma_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_lemma_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_roleset_cxn_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "roleset")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_roleset_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
df_cxn_roleset_lemma_distinctive <- filter_by_n_most_frequent_arg_struc_cxn(corpus_analysis_df, 2)
df_cxn_lemma_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_distinctive, file = file.path(corpus_cleaned_fp, "cxn_lemma_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_roleset_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "roleset")
write.table(df_cxn_roleset_distinctive, file = file.path(corpus_cleaned_fp, "cxn_roleset_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
source(file.path(project_dir, "scripts", "coll.analysis.R"))
dist.collexemes <- function(precbitsexponent = precbitsexponent) {
options(warn = -1)
dists <- 1
input.dc <- 1
fye.mpfr <- "no" # change input to "yes" if you want the FYE calculated as well. Warning: this takes a long time!
file_input = file.choose()
file_input_base <- basename(file_input)
file_output <- file.path(project_dir, "results_analysis", "reproduced_analyses", file_input_base)
file_output <- paste0(gsub("\\..*", "", file_output), "_reproduced_analysis.csv")
input.matrix <- read.table(file_input, header = TRUE, sep = "\t", quote = "", comment.char = "")
if (input.dc == 1) { # DCA
interim <- t(table(input.matrix))
input.matrix <- data.frame(
as.vector(interim[,1]),
as.vector(interim[,2]), row.names = rownames(interim))
colnames(input.matrix) <- colnames(interim)
} else {
temp <- colnames(input.matrix)[2:3]
input.matrix <- data.frame(
as.vector(input.matrix[,2]),
as.vector(input.matrix[,3]), row.names = input.matrix[,1])
colnames(input.matrix) <- temp
}
construction1.name <- colnames(input.matrix)[1]; construction2.name <- colnames(input.matrix)[2]
# computation
options(warn=-1)
pearson.residuals <- chisq.test(input.matrix, correct=FALSE)$residuals[,1]
all.2.by.2.matrices <- apply(
input.matrix, 1,
\(af) { matrix(c(af, colSums(input.matrix)-af), byrow=TRUE, ncol=2) },
simplify=FALSE)
if (fye.mpfr=="yes") {
FYE.values <- lapply(all.2.by.2.matrices,
\(af) fisher.test.mpfr(af))
}
glms <- lapply(all.2.by.2.matrices,
\(af) glm(rbind(af[1,], af[2,]) ~ c(1:2), family=binomial))
log.odds.ratios <- -sapply(glms, coefficients)[2,]
log.likelihood.values <- sapply(glms, "[[", "null.deviance")
mi.scores <- sapply(all.2.by.2.matrices,
\(af) log2(af[1,1] / chisq.test(af, correct=FALSE)$exp[1,1]))
delta.p.constr.cues.word <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[,1]) - af[1,2]/sum(af[,2]))
delta.p.word.cues.constr <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[1,]) - af[2,1]/sum(af[2,]))
relations <- sapply(pearson.residuals,
\(af) switch(sign(af)+2, construction2.name, "chance", construction1.name))
# output
output.table <- data.frame(WORD=rownames(input.matrix), CONSTRUCTION1=input.matrix[,1], CONSTRUCTION2=input.matrix[,2], row.names=NULL)
output.table <- data.frame(output.table, PREFERENCE=relations, LLR=log.likelihood.values, PEARSONRESID=pearson.residuals,
LOGODDSRATIO=log.odds.ratios, MI=mi.scores,
DELTAPC2W=delta.p.constr.cues.word, DELTAPW2C=delta.p.word.cues.constr, row.names=NULL)
if (fye.mpfr=="yes") {
output.table <- data.frame(output.table,
# FYE=sapply(FYE.values, formatMpfr, digits=12))
FYE=sapply(sapply(FYE.values, \(af) -log10(af)), asNumeric))
}
colnames(output.table)[2:3] <- c(construction2.name, construction1.name)
output.table <- output.table[order(output.table$PREFERENCE, -output.table$LOGODDSRATIO),]
write.table(output.table, file=file.path(file_output), sep="\t", row.names=FALSE, col.names=TRUE, quote=FALSE)
cat("\n\nThe results are in the file called ", basename(file_output), ".\n")
plot(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, type="n",
xlab="Logged co-occurrence frequency", ylab="Association (log odds ratio)")
grid(); abline(h=0, lty=2); abline(v=0, lty=2)
text(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, output.table$WORD, font=1)
}
dist.collexemes()
source(file.path(project_dir, "scripts", "coll.analysis.R"))
dist.collexemes <- function(precbitsexponent = precbitsexponent) {
options(warn = -1)
dists <- 1
input.dc <- 1
fye.mpfr <- "no" # change input to "yes" if you want the FYE calculated as well. Warning: this takes a long time!
file_input = file.choose()
file_input_base <- basename(file_input)
file_output <- file.path(project_dir, "results_analysis", "reproduced_analyses", file_input_base)
file_output <- paste0(gsub("\\..*", "", file_output), "_reproduced_analysis.csv")
input.matrix <- read.table(file_input, header = TRUE, sep = "\t", quote = "", comment.char = "")
if (input.dc == 1) { # DCA
interim <- t(table(input.matrix))
input.matrix <- data.frame(
as.vector(interim[,1]),
as.vector(interim[,2]), row.names = rownames(interim))
colnames(input.matrix) <- colnames(interim)
} else {
temp <- colnames(input.matrix)[2:3]
input.matrix <- data.frame(
as.vector(input.matrix[,2]),
as.vector(input.matrix[,3]), row.names = input.matrix[,1])
colnames(input.matrix) <- temp
}
construction1.name <- colnames(input.matrix)[1]; construction2.name <- colnames(input.matrix)[2]
# computation
options(warn=-1)
pearson.residuals <- chisq.test(input.matrix, correct=FALSE)$residuals[,1]
all.2.by.2.matrices <- apply(
input.matrix, 1,
\(af) { matrix(c(af, colSums(input.matrix)-af), byrow=TRUE, ncol=2) },
simplify=FALSE)
if (fye.mpfr=="yes") {
FYE.values <- lapply(all.2.by.2.matrices,
\(af) fisher.test.mpfr(af))
}
glms <- lapply(all.2.by.2.matrices,
\(af) glm(rbind(af[1,], af[2,]) ~ c(1:2), family=binomial))
log.odds.ratios <- -sapply(glms, coefficients)[2,]
log.likelihood.values <- sapply(glms, "[[", "null.deviance")
mi.scores <- sapply(all.2.by.2.matrices,
\(af) log2(af[1,1] / chisq.test(af, correct=FALSE)$exp[1,1]))
delta.p.constr.cues.word <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[,1]) - af[1,2]/sum(af[,2]))
delta.p.word.cues.constr <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[1,]) - af[2,1]/sum(af[2,]))
relations <- sapply(pearson.residuals,
\(af) switch(sign(af)+2, construction2.name, "chance", construction1.name))
# output
output.table <- data.frame(WORD=rownames(input.matrix), CONSTRUCTION1=input.matrix[,1], CONSTRUCTION2=input.matrix[,2], row.names=NULL)
output.table <- data.frame(output.table, PREFERENCE=relations, LLR=log.likelihood.values, PEARSONRESID=pearson.residuals,
LOGODDSRATIO=log.odds.ratios, MI=mi.scores,
DELTAPC2W=delta.p.constr.cues.word, DELTAPW2C=delta.p.word.cues.constr, row.names=NULL)
if (fye.mpfr=="yes") {
output.table <- data.frame(output.table,
# FYE=sapply(FYE.values, formatMpfr, digits=12))
FYE=sapply(sapply(FYE.values, \(af) -log10(af)), asNumeric))
}
colnames(output.table)[2:3] <- c(construction2.name, construction1.name)
output.table <- output.table[order(output.table$PREFERENCE, -output.table$LOGODDSRATIO),]
write.table(output.table, file=file.path(file_output), sep="\t", row.names=FALSE, col.names=TRUE, quote=FALSE)
cat("\n\nThe results are in the file called ", basename(file_output), ".\n")
plot(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, type="n",
xlab="Logged co-occurrence frequency", ylab="Association (log odds ratio)")
grid(); abline(h=0, lty=2); abline(v=0, lty=2)
text(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, output.table$WORD, font=1)
}
dist.collexemes()
# Use the project root directory as a base for other file paths
analysis_fp <- file.path(project_dir, "results_analysis", "reproduced_analyses")
# Load the roleset csv file
results_roleset_cxnDT <- read.csv(file.path(analysis_fp, "cxn_roleset_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_roleset_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_roleset_cxnDT$PREFERENCE)
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_roleset_cxnDT[results_roleset_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the FYE column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_roleset_preference_list[[c]] <- subset_df
}
write.table(cxn_roleset_preference_list$`arg0(np)-v(v)-arg1(np)-arg2(pp)`, file = file.path(analysis_fp, "results_arg0(np)-v(v)-arg1(np)-arg2(pp)_roleset_distinctive_reproduced_analysis.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_roleset_preference_list$`arg0(np)-v(v)-arg2(np)-arg1(np)`, file = file.path(analysis_fp, "results_arg0(np)-v(v)-arg2(np)-arg1(np)_roleset_distinctive_reproduced_analysis.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
results_lemma_cxnDT <- read.csv(file.path(analysis_fp, "cxn_lemma_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_lemma_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_lemma_cxnDT$PREFERENCE)
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_lemma_cxnDT[results_lemma_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the FYE column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_lemma_preference_list[[c]] <- subset_df
}
write.table(cxn_lemma_preference_list$`arg0(np)-v(v)-arg1(np)-arg2(pp)`, file = file.path(analysis_fp, "results_arg0(np)-v(v)-arg1(np)-arg2(pp)_lemma_distinctive_reproduced_analysis.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_lemma_preference_list$`arg0(np)-v(v)-arg2(np)-arg1(np)`, file = file.path(analysis_fp, "results_arg0(np)-v(v)-arg2(np)-arg1(np)_lemma_distinctive_reproduced_analysis.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
source(file.path(project_dir, "scripts", "coll.analysis.R"))
dist.collexemes <- function(precbitsexponent = precbitsexponent) {
options(warn = -1)
dists <- 1
input.dc <- 1
fye.mpfr <- "no" # change input to "yes" if you want the FYE calculated as well. Warning: this takes a long time!
file_input_base <- basename(file_input)
file_output <- file.path(project_dir, "results_analysis", "reproduced_analyses", file_input_base)
file_output <- paste0(gsub("\\..*", "", file_output), "_reproduced_analysis.csv")
input.matrix <- read.table(file_input, header = TRUE, sep = "\t", quote = "", comment.char = "")
if (input.dc == 1) { # DCA
interim <- t(table(input.matrix))
input.matrix <- data.frame(
as.vector(interim[,1]),
as.vector(interim[,2]), row.names = rownames(interim))
colnames(input.matrix) <- colnames(interim)
} else {
temp <- colnames(input.matrix)[2:3]
input.matrix <- data.frame(
as.vector(input.matrix[,2]),
as.vector(input.matrix[,3]), row.names = input.matrix[,1])
colnames(input.matrix) <- temp
}
construction1.name <- colnames(input.matrix)[1]; construction2.name <- colnames(input.matrix)[2]
# computation
options(warn=-1)
pearson.residuals <- chisq.test(input.matrix, correct=FALSE)$residuals[,1]
all.2.by.2.matrices <- apply(
input.matrix, 1,
\(af) { matrix(c(af, colSums(input.matrix)-af), byrow=TRUE, ncol=2) },
simplify=FALSE)
if (fye.mpfr=="yes") {
FYE.values <- lapply(all.2.by.2.matrices,
\(af) fisher.test.mpfr(af))
}
glms <- lapply(all.2.by.2.matrices,
\(af) glm(rbind(af[1,], af[2,]) ~ c(1:2), family=binomial))
log.odds.ratios <- -sapply(glms, coefficients)[2,]
log.likelihood.values <- sapply(glms, "[[", "null.deviance")
mi.scores <- sapply(all.2.by.2.matrices,
\(af) log2(af[1,1] / chisq.test(af, correct=FALSE)$exp[1,1]))
delta.p.constr.cues.word <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[,1]) - af[1,2]/sum(af[,2]))
delta.p.word.cues.constr <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[1,]) - af[2,1]/sum(af[2,]))
relations <- sapply(pearson.residuals,
\(af) switch(sign(af)+2, construction2.name, "chance", construction1.name))
# output
output.table <- data.frame(WORD=rownames(input.matrix), CONSTRUCTION1=input.matrix[,1], CONSTRUCTION2=input.matrix[,2], row.names=NULL)
output.table <- data.frame(output.table, PREFERENCE=relations, LLR=log.likelihood.values, PEARSONRESID=pearson.residuals,
LOGODDSRATIO=log.odds.ratios, MI=mi.scores,
DELTAPC2W=delta.p.constr.cues.word, DELTAPW2C=delta.p.word.cues.constr, row.names=NULL)
if (fye.mpfr=="yes") {
output.table <- data.frame(output.table,
# FYE=sapply(FYE.values, formatMpfr, digits=12))
FYE=sapply(sapply(FYE.values, \(af) -log10(af)), asNumeric))
}
colnames(output.table)[2:3] <- c(construction2.name, construction1.name)
output.table <- output.table[order(output.table$PREFERENCE, -output.table$LOGODDSRATIO),]
write.table(output.table, file=file.path(file_output), sep="\t", row.names=FALSE, col.names=TRUE, quote=FALSE)
cat("\n\nThe results are in the file called ", basename(file_output), ".\n")
plot(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, type="n",
xlab="Logged co-occurrence frequency", ylab="Association (log odds ratio)")
grid(); abline(h=0, lty=2); abline(v=0, lty=2)
text(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, output.table$WORD, font=1)
}
file_input = file.path(project_dir, "data", "corpus_cleaned", "cxn_lemma_distinctive.csv")
dist.collexemes()
file_input = file.path(project_dir, "data", "corpus_cleaned", "cxn_roleset_distinctive.csv")
dist.collexemes()
source(file.path(project_dir, "scripts", "coll.analysis.R"))
dist.collexemes <- function(precbitsexponent = precbitsexponent) {
options(warn = -1)
dists <- 1
input.dc <- 1
fye.mpfr <- "no" # change input to "yes" if you want the FYE calculated as well. Warning: this takes a long time!
file_input_base <- basename(file_input)
file_output <- file.path(project_dir, "results_analysis", "reproduced_analyses", file_input_base)
file_output <- paste0(gsub("\\..*", "", file_output), "_reproduced_analysis.csv")
input.matrix <- read.table(file_input, header = TRUE, sep = "\t", quote = "", comment.char = "")
if (input.dc == 1) { # DCA
interim <- t(table(input.matrix))
input.matrix <- data.frame(
as.vector(interim[,1]),
as.vector(interim[,2]), row.names = rownames(interim))
colnames(input.matrix) <- colnames(interim)
} else {
temp <- colnames(input.matrix)[2:3]
input.matrix <- data.frame(
as.vector(input.matrix[,2]),
as.vector(input.matrix[,3]), row.names = input.matrix[,1])
colnames(input.matrix) <- temp
}
construction1.name <- colnames(input.matrix)[1]; construction2.name <- colnames(input.matrix)[2]
# computation
options(warn=-1)
pearson.residuals <- chisq.test(input.matrix, correct=FALSE)$residuals[,1]
all.2.by.2.matrices <- apply(
input.matrix, 1,
\(af) { matrix(c(af, colSums(input.matrix)-af), byrow=TRUE, ncol=2) },
simplify=FALSE)
if (fye.mpfr=="yes") {
FYE.values <- lapply(all.2.by.2.matrices,
\(af) fisher.test.mpfr(af))
}
glms <- lapply(all.2.by.2.matrices,
\(af) glm(rbind(af[1,], af[2,]) ~ c(1:2), family=binomial))
log.odds.ratios <- -sapply(glms, coefficients)[2,]
log.likelihood.values <- sapply(glms, "[[", "null.deviance")
mi.scores <- sapply(all.2.by.2.matrices,
\(af) log2(af[1,1] / chisq.test(af, correct=FALSE)$exp[1,1]))
delta.p.constr.cues.word <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[,1]) - af[1,2]/sum(af[,2]))
delta.p.word.cues.constr <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[1,]) - af[2,1]/sum(af[2,]))
relations <- sapply(pearson.residuals,
\(af) switch(sign(af)+2, construction2.name, "chance", construction1.name))
# output
output.table <- data.frame(WORD=rownames(input.matrix), CONSTRUCTION1=input.matrix[,1], CONSTRUCTION2=input.matrix[,2], row.names=NULL)
output.table <- data.frame(output.table, PREFERENCE=relations, LLR=log.likelihood.values, PEARSONRESID=pearson.residuals,
LOGODDSRATIO=log.odds.ratios, MI=mi.scores,
DELTAPC2W=delta.p.constr.cues.word, DELTAPW2C=delta.p.word.cues.constr, row.names=NULL)
if (fye.mpfr=="yes") {
output.table <- data.frame(output.table,
# FYE=sapply(FYE.values, formatMpfr, digits=12))
FYE=sapply(sapply(FYE.values, \(af) -log10(af)), asNumeric))
}
colnames(output.table)[2:3] <- c(construction2.name, construction1.name)
output.table <- output.table[order(output.table$PREFERENCE, -output.table$LOGODDSRATIO),]
write.table(output.table, file=file.path(file_output), sep="\t", row.names=FALSE, col.names=TRUE, quote=FALSE)
cat("\n\nThe results are in the file called ", basename(file_output), "in the following location: ", file_output, ".\n")
plot(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, type="n",
xlab="Logged co-occurrence frequency", ylab="Association (log odds ratio)")
grid(); abline(h=0, lty=2); abline(v=0, lty=2)
text(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, output.table$WORD, font=1)
}
file_input = file.path(project_dir, "data", "corpus_cleaned", "cxn_lemma_distinctive.csv")
dist.collexemes()
file_input = file.path(project_dir, "data", "corpus_cleaned", "cxn_roleset_distinctive.csv")
dist.collexemes()
# R Scripts that auto runs a collostructional analysis on a PropBank-annotated corpus and generates the necessary files for analysis
# Import necessary libraries
library(jsonlite)
library(dplyr)
library(here)
# Get the path to the project root directory
project_dir <- here::here()
# Run the files
source(file.path(project_dir, "scripts", "utils.R"))
source(file.path(project_dir, "scripts", "load_data.R"))
source(file.path(project_dir, "scripts", "clean_data.R"))
source(file.path(project_dir, "scripts", "run.analysis.auto_data.R"))
# R Scripts that auto runs a collostructional analysis on a PropBank-annotated corpus and generates the necessary files for analysis
# Import necessary libraries
library(jsonlite)
library(dplyr)
library(here)
# Get the path to the project root directory
project_dir <- here::here()
# Run the files
source(file.path(project_dir, "scripts", "utils.R"))
pause(5)
# R Scripts that auto runs a collostructional analysis on a PropBank-annotated corpus and generates the necessary files for analysis
# Import necessary libraries
library(jsonlite)
library(dplyr)
library(here)
# Get the path to the project root directory
project_dir <- here::here()
# Run the files
source(file.path(project_dir, "scripts", "utils.R"))
Sys.sleep(5)
source(file.path(project_dir, "scripts", "load_data.R"))
Sys.sleep(5)
source(file.path(project_dir, "scripts", "clean_data.R"))
Sys.sleep(5)
source(file.path(project_dir, "scripts", "run.analysis.auto_data.R"))
source(file.path(project_dir, "scripts", "coll.analysis.R"))
dist.collexemes <- function(precbitsexponent = precbitsexponent) {
options(warn = -1)
dists <- 1
input.dc <- 1
fye.mpfr <- "no" # change input to "yes" if you want the FYE calculated as well. Warning: this takes a long time!
file_input_base <- basename(file_input)
file_output <- file.path(project_dir, "results_analysis", "reproduced_analyses", file_input_base)
file_output <- paste0(gsub("\\..*", "", file_output), "_reproduced_analysis.csv")
input.matrix <- read.table(file_input, header = TRUE, sep = "\t", quote = "", comment.char = "")
if (input.dc == 1) { # DCA
interim <- t(table(input.matrix))
input.matrix <- data.frame(
as.vector(interim[,1]),
as.vector(interim[,2]), row.names = rownames(interim))
colnames(input.matrix) <- colnames(interim)
} else {
temp <- colnames(input.matrix)[2:3]
input.matrix <- data.frame(
as.vector(input.matrix[,2]),
as.vector(input.matrix[,3]), row.names = input.matrix[,1])
colnames(input.matrix) <- temp
}
construction1.name <- colnames(input.matrix)[1]; construction2.name <- colnames(input.matrix)[2]
# computation
options(warn=-1)
pearson.residuals <- chisq.test(input.matrix, correct=FALSE)$residuals[,1]
all.2.by.2.matrices <- apply(
input.matrix, 1,
\(af) { matrix(c(af, colSums(input.matrix)-af), byrow=TRUE, ncol=2) },
simplify=FALSE)
if (fye.mpfr=="yes") {
FYE.values <- lapply(all.2.by.2.matrices,
\(af) fisher.test.mpfr(af))
}
glms <- lapply(all.2.by.2.matrices,
\(af) glm(rbind(af[1,], af[2,]) ~ c(1:2), family=binomial))
log.odds.ratios <- -sapply(glms, coefficients)[2,]
log.likelihood.values <- sapply(glms, "[[", "null.deviance")
mi.scores <- sapply(all.2.by.2.matrices,
\(af) log2(af[1,1] / chisq.test(af, correct=FALSE)$exp[1,1]))
delta.p.constr.cues.word <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[,1]) - af[1,2]/sum(af[,2]))
delta.p.word.cues.constr <- sapply(all.2.by.2.matrices,
\(af) af[1,1]/sum(af[1,]) - af[2,1]/sum(af[2,]))
relations <- sapply(pearson.residuals,
\(af) switch(sign(af)+2, construction2.name, "chance", construction1.name))
# output
output.table <- data.frame(WORD=rownames(input.matrix), CONSTRUCTION1=input.matrix[,1], CONSTRUCTION2=input.matrix[,2], row.names=NULL)
output.table <- data.frame(output.table, PREFERENCE=relations, LLR=log.likelihood.values, PEARSONRESID=pearson.residuals,
LOGODDSRATIO=log.odds.ratios, MI=mi.scores,
DELTAPC2W=delta.p.constr.cues.word, DELTAPW2C=delta.p.word.cues.constr, row.names=NULL)
if (fye.mpfr=="yes") {
output.table <- data.frame(output.table,
# FYE=sapply(FYE.values, formatMpfr, digits=12))
FYE=sapply(sapply(FYE.values, \(af) -log10(af)), asNumeric))
}
colnames(output.table)[2:3] <- c(construction2.name, construction1.name)
output.table <- output.table[order(output.table$PREFERENCE, -output.table$LOGODDSRATIO),]
write.table(output.table, file=file.path(file_output), sep="\t", row.names=FALSE, col.names=TRUE, quote=FALSE)
cat("\n\nThe results are in the file called ", basename(file_output), "in the following location: ", file_output, ".\n")
plot(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, type="n",
xlab="Logged co-occurrence frequency", ylab="Association (log odds ratio)")
grid(); abline(h=0, lty=2); abline(v=0, lty=2)
text(log2(output.table[,2]+output.table[,3]), output.table$LOGODDSRATIO, output.table$WORD, font=1)
}
file_input = file.path(project_dir, "data", "corpus_cleaned", "cxn_lemma_distinctive.csv")
dist.collexemes()
file_input = file.path(project_dir, "data", "corpus_cleaned", "cxn_roleset_distinctive.csv")
dist.collexemes()
# R Scripts that auto runs a collostructional analysis on a PropBank-annotated corpus and generates the necessary files for analysis
# Import necessary libraries
library(jsonlite)
library(dplyr)
library(here)
# Get the path to the project root directory
project_dir <- here::here()
# Run the files
source(file.path(project_dir, "scripts", "utils.R"))
Sys.sleep(1)
source(file.path(project_dir, "scripts", "load_data.R"))
Sys.sleep(1)
source(file.path(project_dir, "scripts", "clean_data.R"))
Sys.sleep(15)
source(file.path(project_dir, "scripts", "run.analysis.auto_data.R"))
# R Scripts that auto runs a collostructional analysis on a PropBank-annotated corpus and generates the necessary files for analysis
# Import necessary libraries
library(jsonlite)
library(dplyr)
library(here)
# Get the path to the project root directory
project_dir <- here::here()
# Run the files
source(file.path(project_dir, "scripts", "utils.R"))
Sys.sleep(1)
source(file.path(project_dir, "scripts", "load_data.R"))
Sys.sleep(1)
source(file.path(project_dir, "scripts", "clean_data.R"))
Sys.sleep(1)
source(file.path(project_dir, "scripts", "coll.analysis.r"))
Sys.sleep(1)
source(file.path(project_dir, "scripts", "run.analysis.auto_data.R"))
