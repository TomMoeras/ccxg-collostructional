cxn1 = constructions_df$constructions[1]
cxn2 = constructions_df$constructions[2]
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_roleset_cxnDT[results_roleset_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the LOGODDSRATIO column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_roleset_preference_list[[c]] <- subset_df
}
write.table(cxn_roleset_preference_list[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_roleset_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_roleset_preference_list[[cxn2]], file = file.path(analysis_fp, str_glue("results_{cxn2}_roleset_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
results_lemma_cxnDT <- read.csv(file.path(analysis_fp, "cxn_lemma_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_lemma_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_lemma_cxnDT$PREFERENCE)
constructions_df = data.frame(constructions)
cxn1 = constructions_df$constructions[1]
cxn2 = constructions_df$constructions[2]
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_lemma_cxnDT[results_lemma_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the LOGODDSRATIO column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_lemma_preference_list[[c]] <- subset_df
}
write.table(cxn_lemma_preference_list[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_lemma_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_lemma_preference_list[[cxn2]], file = file.path(analysis_fp, str_glue("results_{cxn2}_lemma_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
######
# export the same lists but only with verbs that occur in both constructions
# Load the roleset csv file
mix_results_roleset <- read.table(file.path(analysis_fp, str_glue("results_{cxn1}_roleset_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
cxn1 <- colnames(mix_results_roleset)[2]
cxn2 <- colnames(mix_results_roleset)[3]
mix_results_roleset <- data.frame(mix_results_roleset)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1) > 0 & !!as.symbol(cxn2) > 0)
write.table(mix_results_roleset[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_mixed_rolesets.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the roleset csv file
mix_results_roleset <- read.table(file.path(analysis_fp, str_glue("results_{cxn2}_roleset_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
# Use the project root directory as a base for other file paths
analysis_fp <- file.path(project_dir, "results_analysis", "reproduced_analyses")
# Load the roleset csv file
results_roleset_cxnDT <- read.table(file.path(analysis_fp, "cxn_roleset_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_roleset_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_roleset_cxnDT$PREFERENCE)
constructions_df = data.frame(constructions)
cxn1 = constructions_df$constructions[1]
cxn2 = constructions_df$constructions[2]
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_roleset_cxnDT[results_roleset_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the LOGODDSRATIO column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_roleset_preference_list[[c]] <- subset_df
}
write.table(cxn_roleset_preference_list[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_roleset_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_roleset_preference_list[[cxn2]], file = file.path(analysis_fp, str_glue("results_{cxn2}_roleset_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
results_lemma_cxnDT <- read.csv(file.path(analysis_fp, "cxn_lemma_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_lemma_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_lemma_cxnDT$PREFERENCE)
constructions_df = data.frame(constructions)
cxn1 = constructions_df$constructions[1]
cxn2 = constructions_df$constructions[2]
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_lemma_cxnDT[results_lemma_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the LOGODDSRATIO column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_lemma_preference_list[[c]] <- subset_df
}
write.table(cxn_lemma_preference_list[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_lemma_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_lemma_preference_list[[cxn2]], file = file.path(analysis_fp, str_glue("results_{cxn2}_lemma_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
######
# export the same lists but only with verbs that occur in both constructions
# Load the roleset csv file
mix_results_roleset <- read.table(file.path(analysis_fp, str_glue("results_{cxn1}_roleset_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
cxn1_mixed <- colnames(mix_results_roleset)[2]
cxn2_mixed <- colnames(mix_results_roleset)[3]
mix_results_roleset <- data.frame(mix_results_roleset)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_roleset[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_mixed_rolesets.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the roleset csv file
mix_results_roleset <- read.table(file.path(analysis_fp, str_glue("results_{cxn2}_roleset_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
mix_results_roleset <- data.frame(mix_results_roleset)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_roleset[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn2}_mixed_rolesets.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
mix_results_lemma <- read.table(file.path(analysis_fp, str_glue("results_{cxn1}_lemma_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
mix_results_lemma <- data.frame(mix_results_lemma)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_lemma[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_mixed_lemma.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
mix_results_lemma <- read.table(file.path(analysis_fp, str_glue("results_{cxn2}_lemma_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
mix_results_lemma <- data.frame(mix_results_lemma)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_lemma[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn2}_mixed_lemma.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Use the project root directory as a base for other file paths
analysis_fp <- file.path(project_dir, "results_analysis", "reproduced_analyses")
# Load the roleset csv file
results_roleset_cxnDT <- read.table(file.path(analysis_fp, "cxn_roleset_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_roleset_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_roleset_cxnDT$PREFERENCE)
constructions_df = data.frame(constructions)
cxn1 = constructions_df$constructions[1]
cxn2 = constructions_df$constructions[2]
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_roleset_cxnDT[results_roleset_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the LOGODDSRATIO column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_roleset_preference_list[[c]] <- subset_df
}
write.table(cxn_roleset_preference_list[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_roleset_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_roleset_preference_list[[cxn2]], file = file.path(analysis_fp, str_glue("results_{cxn2}_roleset_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
results_lemma_cxnDT <- read.csv(file.path(analysis_fp, "cxn_lemma_distinctive_reproduced_analysis.csv"), header=TRUE, sep="\t", quote="", comment.char="")
# Create an empty list to store the new dataframes
cxn_lemma_preference_list = list()
# Get the unique constructions in the "PREFERENCE" column
constructions = unique(results_lemma_cxnDT$PREFERENCE)
constructions_df = data.frame(constructions)
cxn1 = constructions_df$constructions[1]
cxn2 = constructions_df$constructions[2]
# Iterate through each construction
for (c in constructions) {
# Subset the original dataframe to only include rows with the current construction
subset_df = results_lemma_cxnDT[results_lemma_cxnDT$PREFERENCE == c, ]
# Sort the data frame based on the LOGODDSRATIO column
subset_df = subset_df[order(-subset_df$LOGODDSRATIO), ]
# Assign the subsetted dataframe to a new object named after the construction
assign(c, subset_df)
# Append the subsetted dataframe to the list of new dataframes
cxn_lemma_preference_list[[c]] <- subset_df
}
write.table(cxn_lemma_preference_list[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_lemma_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
write.table(cxn_lemma_preference_list[[cxn2]], file = file.path(analysis_fp, str_glue("results_{cxn2}_lemma_distinctive_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
######
# export the same lists but only with verbs that occur in both constructions
# Load the roleset csv file
mix_results_roleset <- read.table(file.path(analysis_fp, str_glue("results_{cxn1}_roleset_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
cxn1_mixed <- colnames(mix_results_roleset)[2]
cxn2_mixed <- colnames(mix_results_roleset)[3]
mix_results_roleset <- data.frame(mix_results_roleset)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_roleset[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_mixed_rolesets_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the roleset csv file
mix_results_roleset <- read.table(file.path(analysis_fp, str_glue("results_{cxn2}_roleset_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
mix_results_roleset <- data.frame(mix_results_roleset)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_roleset[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn2}_mixed_rolesets_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
mix_results_lemma <- read.table(file.path(analysis_fp, str_glue("results_{cxn1}_lemma_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
mix_results_lemma <- data.frame(mix_results_lemma)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_lemma[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn1}_mixed_lemma_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# Load the lemma csv file
mix_results_lemma <- read.table(file.path(analysis_fp, str_glue("results_{cxn2}_lemma_distinctive_reproduced_analysis.csv")), header=TRUE, sep="\t", quote="", comment.char="")
mix_results_lemma <- data.frame(mix_results_lemma)
# Filter to only larger than 0 in cxn column
mix_results_roleset <- mix_results_roleset %>%
filter(!!as.symbol(cxn1_mixed) > 0 & !!as.symbol(cxn2_mixed) > 0)
write.table(mix_results_lemma[[cxn1]], file = file.path(analysis_fp, str_glue("results_{cxn2}_mixed_lemma_reproduced_analysis.csv")), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
# R Scripts that auto runs a collostructional analysis on a PropBank-annotated corpus and generates the necessary files for analysis
# Import necessary libraries and install if necessary
library(jsonlite)
library(dplyr)
library(here)
library(tidyr)
library(stringr)
library(rlang)
# Get the path to the project root directory
project_dir <- here::here()
# Run the files automatically
source(file.path(project_dir, "scripts", "utils.R")) # loads several functions used during data processing and analysis
source(file.path(project_dir, "scripts", "load_data.R")) # loads the .json and turns it into a workable data frame
source(file.path(project_dir, "scripts", "clean_data.R")) # cleans the data and creates data frames used for analysis
source(file.path(project_dir, "scripts", "coll.analysis.r")) # Loads functions needed for the DCA # Copyright (C) 2022 Stefan Th. Gries (Latest changes in this version: 21 August 2022)
##########################################################################################################################################
# IMPORTANT: The run.analysis.auto script does not use the FYE association score by default.
# If you want to use FYE, you have to manually turn it on in the script itself (= change the indicated variable to "yes" instead of "no")
# WARNING: It takes a very long time to perform FYE.
##########################################################################################################################################
source(file.path(project_dir, "scripts", "run.analysis.auto.R")) # Runs the DCA
source(file.path(project_dir, "scripts", "clean_analysis.R"))
View(corpus_analysis_df)
View(cxn_freq_table)
View(freq_table)
freq_table <- data.frame(count_frequency(corpus_analysis_df))
lapply(freq_list, function(x) write.table( freq_list(x), 'test.csv'  , append= T, sep = "\t", col.names = TRUE, quote = FALSE ))
freq_list <- count_frequency(corpus_analysis_df)
lapply(freq_list, function(x) write.table( freq_list(x), 'test.csv'  , append= T, sep = "\t", col.names = TRUE, quote = FALSE ))
freq_list <- count_frequency(corpus_analysis_df)
unlisted_freq <- unlist(freq_list)
write.csv(unlisted_list, "my_list.csv", row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
freq_list <- count_frequency(corpus_analysis_df)
unlisted_freq <- unlist(freq_list)
write.csv(unlisted_freq, "my_list.csv", row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
freq_list
View(freq_list)
for (i in seq_along(freq_list)) {
filename = paste(i, ".csv")
write.csv(freq_list[[i]], filename)
}
View(freq_list)
freq_list(length[[1]])
length(freq_list[[1]])
numbers_df <- data.frame(lemma = character(), roleset = character(), arg_struc_cxn = character(), stringsAsFactors = FALSE)
View(numbers_df)
View(freq_list)
numbers_df <- data.frame(lemma = length(freq_list[[3]]), roleset = character(), arg_struc_cxn = character(), stringsAsFactors = FALSE)
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = character(), roleset = character(), arg_struc_cxn = character(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[1]]), roleset = "verb_run", arg_struc_cxn = "intransitive")
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(number_df) <- c("freq")
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(numbers_df) <- c("freq")
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(numbers_df) <- c("#types")
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(numbers_df) <- c("#types")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "numbers.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_lemma_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_lemma_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_roleset_cxn_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "roleset")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_roleset_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
df_cxn_roleset_lemma_distinctive <- filter_by_n_most_frequent_arg_struc_cxn(corpus_analysis_df, 2)
df_cxn_lemma_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_distinctive, file = file.path(corpus_cleaned_fp, "cxn_lemma_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_roleset_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "roleset")
write.table(df_cxn_roleset_distinctive, file = file.path(corpus_cleaned_fp, "cxn_roleset_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
unique_cxn_list <- unique(corpus_analysis_df$arg_struc_cxn)
df_summary_corpus <- corpus_analysis_df %>%
group_by(lemma) %>%
summarise(roleset)
#Count the frequency of each roleset in each construction
construction_counts <- corpus_analysis_df %>%
group_by(lemma, roleset, arg_struc_cxn) %>%
summarize(count = n())
# Pivot the df
df_summary_corpus <- pivot_wider(construction_counts, names_from = arg_struc_cxn, values_from = count)
df_summary_corpus$total <- rowSums(df_summary_corpus[,3:ncol(df_summary_corpus)], na.rm = TRUE)
cxn_freq_table <- data.frame(sort(freq_table[[1]], decreasing = TRUE, by = "value"))
cxn_freq_df <- data.frame(cxn_freq_table$Var1)
col_order <- c(cxn_freq_df$cxn_freq_table.Var1)
alph_lemma_df <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(alph_lemma_df, file = file.path(corpus_cleaned_fp, "alph_lemma_roleset_cxn.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_summary_corpus <- df_summary_corpus %>%
arrange(desc(total))
corpus_cleaned_overview <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(corpus_cleaned_overview, file = file.path(corpus_cleaned_fp, "corpus_cleaned_summary.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(numbers_df) <- c("#types")
write.table(numbers_df, file = file.path(corpus_cleaned_fp, "numbers.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_lemma_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_lemma_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_roleset_cxn_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "roleset")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_roleset_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
df_cxn_roleset_lemma_distinctive <- filter_by_n_most_frequent_arg_struc_cxn(corpus_analysis_df, 2)
df_cxn_lemma_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_distinctive, file = file.path(corpus_cleaned_fp, "cxn_lemma_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_roleset_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "roleset")
write.table(df_cxn_roleset_distinctive, file = file.path(corpus_cleaned_fp, "cxn_roleset_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
unique_cxn_list <- unique(corpus_analysis_df$arg_struc_cxn)
df_summary_corpus <- corpus_analysis_df %>%
group_by(lemma) %>%
summarise(roleset)
#Count the frequency of each roleset in each construction
construction_counts <- corpus_analysis_df %>%
group_by(lemma, roleset, arg_struc_cxn) %>%
summarize(count = n())
# Pivot the df
df_summary_corpus <- pivot_wider(construction_counts, names_from = arg_struc_cxn, values_from = count)
df_summary_corpus$total <- rowSums(df_summary_corpus[,3:ncol(df_summary_corpus)], na.rm = TRUE)
cxn_freq_table <- data.frame(sort(freq_table[[1]], decreasing = TRUE, by = "value"))
cxn_freq_df <- data.frame(cxn_freq_table$Var1)
col_order <- c(cxn_freq_df$cxn_freq_table.Var1)
alph_lemma_df <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(alph_lemma_df, file = file.path(corpus_cleaned_fp, "alph_lemma_roleset_cxn.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_summary_corpus <- df_summary_corpus %>%
arrange(desc(total))
corpus_cleaned_overview <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(corpus_cleaned_overview, file = file.path(corpus_cleaned_fp, "corpus_cleaned_summary.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(numbers_df) <- c("#types")
write.table(numbers_df, file = file.path(corpus_cleaned_fp, "numbers.rds"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_lemma_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_lemma_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_roleset_cxn_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "roleset")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_roleset_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
df_cxn_roleset_lemma_distinctive <- filter_by_n_most_frequent_arg_struc_cxn(corpus_analysis_df, 2)
df_cxn_lemma_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_distinctive, file = file.path(corpus_cleaned_fp, "cxn_lemma_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_roleset_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "roleset")
write.table(df_cxn_roleset_distinctive, file = file.path(corpus_cleaned_fp, "cxn_roleset_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
unique_cxn_list <- unique(corpus_analysis_df$arg_struc_cxn)
df_summary_corpus <- corpus_analysis_df %>%
group_by(lemma) %>%
summarise(roleset)
#Count the frequency of each roleset in each construction
construction_counts <- corpus_analysis_df %>%
group_by(lemma, roleset, arg_struc_cxn) %>%
summarize(count = n())
# Pivot the df
df_summary_corpus <- pivot_wider(construction_counts, names_from = arg_struc_cxn, values_from = count)
df_summary_corpus$total <- rowSums(df_summary_corpus[,3:ncol(df_summary_corpus)], na.rm = TRUE)
cxn_freq_table <- data.frame(sort(freq_table[[1]], decreasing = TRUE, by = "value"))
cxn_freq_df <- data.frame(cxn_freq_table$Var1)
col_order <- c(cxn_freq_df$cxn_freq_table.Var1)
alph_lemma_df <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(alph_lemma_df, file = file.path(corpus_cleaned_fp, "alph_lemma_roleset_cxn.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_summary_corpus <- df_summary_corpus %>%
arrange(desc(total))
corpus_cleaned_overview <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(corpus_cleaned_overview, file = file.path(corpus_cleaned_fp, "corpus_cleaned_summary.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
source(file.path(project_dir, "scripts", "utils.R"))
# Use the project root directory as a base for other file paths
corpus_cleaned_fp <- file.path(project_dir, "data", "corpus_cleaned")
lemma_rolesets_df <- detect_rolesets_by_lemma(corpus_analysis_df)
freq_list <- count_frequency(corpus_analysis_df)
numbers_df <- data.frame(lemma = integer(), roleset = integer(), arg_struc_cxn = integer(), stringsAsFactors = FALSE)
numbers_df <- numbers_df %>% add_row(lemma = length(freq_list[[3]]), roleset = length(freq_list[[2]]), arg_struc_cxn = length(freq_list[[1]]))
rownames(numbers_df) <- c("#types")
write.table(numbers_df, file = file.path(corpus_cleaned_fp, "numbers.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_lemma_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_lemma_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_roleset_cxn_multiple <- combine_columns(corpus_analysis_df, corpus_analysis_df, "arg_struc_cxn", "roleset")
write.table(df_cxn_lemma_multiple, file = file.path(corpus_cleaned_fp, "cxn_roleset_multiple.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
df_cxn_roleset_lemma_distinctive <- filter_by_n_most_frequent_arg_struc_cxn(corpus_analysis_df, 2)
df_cxn_lemma_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "lemma")
write.table(df_cxn_lemma_distinctive, file = file.path(corpus_cleaned_fp, "cxn_lemma_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_cxn_roleset_distinctive <- combine_columns(df_cxn_roleset_lemma_distinctive, df_cxn_roleset_lemma_distinctive, "arg_struc_cxn", "roleset")
write.table(df_cxn_roleset_distinctive, file = file.path(corpus_cleaned_fp, "cxn_roleset_distinctive.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
#
unique_cxn_list <- unique(corpus_analysis_df$arg_struc_cxn)
df_summary_corpus <- corpus_analysis_df %>%
group_by(lemma) %>%
summarise(roleset)
#Count the frequency of each roleset in each construction
construction_counts <- corpus_analysis_df %>%
group_by(lemma, roleset, arg_struc_cxn) %>%
summarize(count = n())
# Pivot the df
df_summary_corpus <- pivot_wider(construction_counts, names_from = arg_struc_cxn, values_from = count)
df_summary_corpus$total <- rowSums(df_summary_corpus[,3:ncol(df_summary_corpus)], na.rm = TRUE)
cxn_freq_table <- data.frame(sort(freq_table[[1]], decreasing = TRUE, by = "value"))
cxn_freq_df <- data.frame(cxn_freq_table$Var1)
col_order <- c(cxn_freq_df$cxn_freq_table.Var1)
alph_lemma_df <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(alph_lemma_df, file = file.path(corpus_cleaned_fp, "alph_lemma_roleset_cxn.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
df_summary_corpus <- df_summary_corpus %>%
arrange(desc(total))
corpus_cleaned_overview <- select(df_summary_corpus, "lemma", "roleset", "total", c(col_order))
write.table(corpus_cleaned_overview, file = file.path(corpus_cleaned_fp, "corpus_cleaned_summary.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
View(corpus_analysis_df)
# Import necessary libraries
library(jsonlite)
library(dplyr)
library(here)
library(tidyr)
library(stringr)
library(rlang)
# Get the path to the project root directory
project_dir <- here::here()
# Use the project root directory as a base for other file paths
raw_data_file <- file.path(project_dir, "data", "raw_data", "CCxG_Ditrans_10000.json")
# Load the CCxG propbank-annotated .json corpus data
corpus_df <- fromJSON(raw_data_file)
# Convert JSON data to data frame
corpus_df <- as.data.frame(corpus_df)
# Extract the roles from the data frame
roles <- corpus_df[["roles"]]
# Extract the rolesets from the roles data frame
roleset_df <- data.frame(roleset = unlist(lapply(roles, function(x) x$roleset)))
# Remove NA values
roleset_df <- na.omit(roleset_df)
# Extract the rolesets from the roles data frame
lemma_df <- data.frame(lemma = unlist(lapply(roles, function(x) x$lemma)))
# Remove NA values
lemma_df <- na.omit(lemma_df)
add_lemma_column <- function(corpus_df, lemma_df) {
corpus_df$lemma <- lemma_df$lemma
return(corpus_df)
}
corpus_df <- add_lemma_column(corpus_df, lemma_df)
# Function that adds an additional column to a dataframe
# The new column is called argument_structure_construction and is a combination of roleType and pos
add_arg_struct <- function(data_frame) {
# Add a new column called 'argument_structure_construction' to the data frame
data_frame$argument_structure_construction <- sapply(data_frame$roles, function(x) {
# Concatenate the roleType and pos columns into a string like 'arg0(np)'
role_strings <- paste0(x$roleType, "(", x$pos, ")")
# Collapse the role strings into a single string separated by '-'
return(paste(role_strings, collapse = "-"))
})
# Return the modified data frame
return(data_frame)
}
# Run the add add_arg_struct function to the corpus dataframe
corpus_df <- add_arg_struct(corpus_df)
# Function that creates the dataframe used for the analysis
# It combines the argument structure and roleset into a dataframe
combine_arg_struct_and_roleset <- function(corpus, rolesets, lemmas) {
corpus_analysis_df <- data.frame(arg_struc_cxn = corpus$argument_structure_construction, roleset = rolesets$roleset, lemma = lemmas$lemma)
return(corpus_analysis_df)
}
corpus_analysis_df <- combine_arg_struct_and_roleset(corpus_df, roleset_df, lemma_df)
write.table(corpus_analysis_df, file = file.path(project_dir, "data", "raw_data", "raw_corpus_data.csv"), row.names = FALSE, sep = "\t", col.names = TRUE, quote = FALSE)
tlmgr update --all
install.packages("tinytex")
library(tinytex)
tlmgr_update()
install.packages("tinytex")
tinytex::reinstall_tinytex()
